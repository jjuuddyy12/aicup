{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./CSVs/play_style_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "game_styles = [int(i.split(',',2)[-2]) for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = torch.zeros((19,19,4) , dtype=torch.short)\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        x[row,column,3] = 1\n",
    "    x[:,:,2] = torch.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 26615\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "print(f\"Total Games: {n_games}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for game in games:\n",
    "    moves_list = game.split(',')\n",
    "    x.append(prepare_input(moves_list))\n",
    "x = torch.stack(x)\n",
    "y = torch.from_numpy(np.array(game_styles)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26615, 19, 19, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26615])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8184, 9403, 9028])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datset = torch.utils.data.TensorDataset(x , y)\n",
    "train_size = int(len(datset) * .8)\n",
    "valid_size = len(datset) - train_size\n",
    "train_set, valid_set = torch.utils.data.random_split(datset , [train_size , valid_size] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x:torch.nn) -> torch.nn:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x.transpose(0,1)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x).transpose(0,1)\n",
    "    \n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads=8, dropout=0, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model , d_model * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self , target , memory , **kwargs):\n",
    "        target = self.norm1(target + self.self_attn(target , memory , memory , need_weights=False)[0])\n",
    "        target = self.norm2(target + self.feed_forward(target))\n",
    "        return target\n",
    "\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 4\n",
    "        self.atten_size = 384\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(4 , self.atten_size),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "        self.position_encoding = PositionalEncoding(self.atten_size , dropout=0 , max_len=361)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.atten_size,  nhead=6 , dim_feedforward=1024 , batch_first=True , activation=\"gelu\")\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=5)\n",
    "\n",
    "        # self.output_conv = nn.Conv1d(self.atten_size , 1 , kernel_size=1 , stride=1 , padding=0)\n",
    "        # self.output_linear = nn.Linear(self.atten_size , 1)\n",
    "\n",
    "    def forward(self , x):\n",
    "        # [batch , w , h , dim]\n",
    "        x = self.input_layer(x).flatten(1,2)\n",
    "\n",
    "        # [batch , w * h , dim]\n",
    "        x = self.position_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # x = x.transpose(1 , 2)\n",
    "        # [batch , dim , w * h]\n",
    "        # x = self.output_conv(x).squeeze(1)\n",
    "        # [batch , w * h]\n",
    "\n",
    "        # return self.output_linear(x).squeeze(-1)\n",
    "        return x\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 32\n",
    "        self.atten_size = 384\n",
    "\n",
    "        self.embedding_model = EmbeddingModel()\n",
    "        \n",
    "        self.atten_layer = nn.TransformerDecoder(AttentionBlock(self.atten_size), num_layers=3)\n",
    "        self.query = nn.Parameter(torch.rand(1,self.atten_size,))\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(self.atten_size , 3),\n",
    "            # nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self , x):\n",
    "        x = self.embedding_model(x)\n",
    "\n",
    "        query = self.query.repeat(x.shape[0] , 1 , 1)\n",
    "\n",
    "        x = self.atten_layer(query , x).squeeze(1)\n",
    "        return self.output_layer(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [5:06:00<00:00, 61.20s/it, train_loss=0.628, valid_loss=0.727, valid_f1=0.708, valid_accuracy=0.709]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"model/play_style_backup2.pt\") , strict=False)\n",
    "model.embedding_model.load_state_dict(torch.load(\"model/play_kyu_large_backup.pt\") , strict=False)\n",
    "# for param in model.embedding_model.transformer_encoder.layers[2:3].parameters():\n",
    "#     param.requires_grad = False\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": model.embedding_model.input_layer.parameters(), \"lr\": 1e-6},\n",
    "    {\"params\": model.embedding_model.transformer_encoder.layers[:3].parameters(), \"lr\": 1e-6},\n",
    "    {\"params\": model.embedding_model.transformer_encoder.layers[3:].parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": model.atten_layer.parameters(), \"lr\": 2e-5},\n",
    "    {\"params\": model.query, \"lr\": 2e-5},\n",
    "    {\"params\": model.output_layer.parameters(), \"lr\": 2e-5},\n",
    "])\n",
    "scheduler =  torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set , batch_size=64 , shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_set , batch_size=64)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "from sklearn.metrics import f1_score , accuracy_score\n",
    "\n",
    "pbar = tqdm(range(300))\n",
    "best_loss = 1000\n",
    "for i in pbar:\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for x , y in train_dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device)\n",
    "        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "            output = model(x)\n",
    "\n",
    "            loss = loss_fn(output , y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    \n",
    "    metrics_true = []\n",
    "    metrics_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x , y in valid_dataloader:\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device)\n",
    "            \n",
    "            output = model(x)\n",
    "            loss = loss_fn(output , y)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "            metrics_true.extend(y.cpu().flatten().tolist())\n",
    "            metrics_pred.extend(torch.argmax(output , dim=-1).cpu().flatten().tolist())\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "\n",
    "    valid_f_score = f1_score(metrics_true , metrics_pred , average='macro')\n",
    "    valid_accuracy = accuracy_score(metrics_true , metrics_pred)\n",
    "\n",
    "    pbar.set_postfix({\"train_loss\":train_loss , \"valid_loss\":valid_loss , \"valid_f1\": valid_f_score , \"valid_accuracy\":valid_accuracy} )\n",
    "    pbar.refresh()\n",
    "\n",
    "    if best_loss > valid_loss:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model.state_dict() , \"model/play_style.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best valid accuracy 0.744"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
