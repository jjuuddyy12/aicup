{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./CSVs/dan_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = torch.zeros((19,19,4) , dtype=torch.int8)\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        # last_move_column = coordinates[moves[-1][2]]\n",
    "        # last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,3] = 1\n",
    "    x[:,:,2] = torch.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 100160, Total Moves: 22853380\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "n_moves = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "    moves_list = game.split(',')\n",
    "    for move in moves_list:\n",
    "        n_moves += 1\n",
    "print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100160/100160 [54:13<00:00, 30.78it/s] \n"
     ]
    }
   ],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "\n",
    "# def get_one_game(args):\n",
    "#     (game_index , moves_list) = args\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for count, move in enumerate(moves_list):\n",
    "#         if (game_index + count) % 5 == 0: #% 20 == 0:\n",
    "#             x.append(prepare_input(moves_list[:count]))\n",
    "#             y.append(prepare_label(moves_list[count]))\n",
    "#     return torch.stack(x) , torch.tensor(y)\n",
    "\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "#     outputs = executor.map(get_one_game, [(game_index , game.split(',')) for game_index , game in enumerate(games)] , chunksize=200)\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for (output_x , output_y) in tqdm(outputs , total=n_games):\n",
    "#         x.append(output_x)\n",
    "#         y.append(output_y)\n",
    "\n",
    "#     x = torch.concat(x, dim=0)\n",
    "#     y = torch.concat(y, dim=0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "x = []\n",
    "y = []\n",
    "for game_index , game in tqdm(enumerate(games) , total=n_games):\n",
    "    moves_list = game.split(',')\n",
    "    for count, move in enumerate(moves_list):\n",
    "        if (game_index + count) % 5 == 0: #% 20 == 0:\n",
    "            x.append(prepare_input(moves_list[:count]))\n",
    "            y.append(prepare_label(moves_list[count]))\n",
    "x = torch.stack(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4570718, 19, 19, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4570718])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datset = torch.utils.data.TensorDataset(x , y)\n",
    "train_size = int(len(datset) * .8)\n",
    "valid_size = len(datset) - train_size\n",
    "train_set, valid_set = torch.utils.data.random_split(datset , [train_size , valid_size] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x:torch.nn) -> torch.nn:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x.transpose(0,1)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x).transpose(0,1)\n",
    "\n",
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(self, dim):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.cnn = nn.Sequential(\n",
    "#             nn.Conv2d(dim , dim , kernel_size=3 , stride=1 , padding=1),\n",
    "#             nn.Softplus(),\n",
    "#             nn.Conv2d(dim , dim , kernel_size=3 , stride=1 , padding=1),\n",
    "#         )\n",
    "#         # self.activate = nn.Softplus()\n",
    "#         self.norm = nn.InstanceNorm2d(dim , momentum=0.01 , affine=True , track_running_stats=True)\n",
    "\n",
    "#     def forward(self , x):\n",
    "#         return self.norm(x + self.cnn(x))#self.activate()\n",
    "    \n",
    "# class AttentionBlock(nn.Module):\n",
    "#     def __init__(self, d_model):\n",
    "#         super().__init__()\n",
    "#         self.self_attn = nn.MultiheadAttention(d_model, num_heads=8, dropout=0, batch_first=True)\n",
    "#         self.norm1 = nn.LayerNorm(d_model)\n",
    "#         self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "#         self.feed_forward = nn.Sequential(\n",
    "#             nn.Linear(d_model , d_model * 2),\n",
    "#             nn.Softplus(),\n",
    "#             nn.Linear(d_model * 2, d_model),\n",
    "#         )\n",
    "\n",
    "#     def forward(self , target , memory , **kwargs):\n",
    "#         target = self.norm1(target + self.self_attn(target , memory , memory , need_weights=False)[0])\n",
    "#         target = self.norm2(target + self.feed_forward(target))\n",
    "#         return target\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.atten_size = 512\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(4 , self.atten_size),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "        self.position_encoding = PositionalEncoding(self.atten_size , dropout=0 , max_len=361)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.atten_size,  nhead=8 , dim_feedforward=2048 , batch_first=True , activation=\"gelu\")\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=5)\n",
    "\n",
    "        # self.output_conv = nn.Conv1d(self.atten_size , 1 , kernel_size=1 , stride=1 , padding=0)\n",
    "        self.output_linear = nn.Linear(self.atten_size , 1)\n",
    "\n",
    "    def forward(self , x):\n",
    "        # [batch , w , h , dim]\n",
    "        x = self.input_layer(x).flatten(1,2)\n",
    "\n",
    "        # [batch , w * h , dim]\n",
    "        x = self.position_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # x = x.transpose(1 , 2)\n",
    "        # [batch , dim , w * h]\n",
    "        # x = self.output_conv(x).squeeze(1)\n",
    "        # [batch , w * h]\n",
    "\n",
    "        return self.output_linear(x).squeeze(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  23%|██▎       | 23/100 [90:31:51<301:11:11, 14081.44s/it, train progress=971/28567, valid progress=7142/7142, train_loss=1.92, valid_loss=1.87, valid_f1=0.503, valid_accuracy=0.498]  "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "# model.load_state_dict(torch.load(\"model/play_dan_xxlarge_backup.pt\") , strict=False)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "scheduler =  torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.93)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set , batch_size=128 , shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_set , batch_size=128)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "from sklearn.metrics import f1_score , accuracy_score\n",
    "\n",
    "dict_state = {\n",
    "    \"train progress\" : \"0/0\",\n",
    "    \"valid progress\" : \"0/0\",\n",
    "\n",
    "    \"train_loss\" : \"na\",\n",
    "    \"valid_loss\" : \"na\",\n",
    "    \"valid_f1\" : \"na\",\n",
    "    \"valid_accuracy\" : \"na\",\n",
    "}\n",
    "\n",
    "with(tqdm(range(100), desc=\"Epochs\") as pbar) :\n",
    "\n",
    "    dict_state.update({\n",
    "        \"train progress\" : f\"0/{len(train_dataloader)}\",\n",
    "        \"valid progress\" : f\"0/{len(valid_dataloader)}\",\n",
    "        })\n",
    "    pbar.set_postfix(dict_state , refresh=True)\n",
    "\n",
    "    best_loss = 100\n",
    "    for i in pbar:\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        for i , (x , y) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device)\n",
    "            with torch.cuda.amp.autocast(dtype=torch.float16 , enabled=True):\n",
    "                output = model(x)\n",
    "\n",
    "                loss = loss_fn(output , y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            dict_state.update({\"train progress\" : f\"{i+1}/{len(train_dataloader)}\"})\n",
    "            pbar.set_postfix(dict_state , refresh=(i % 5) == 0)\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        metrics_true = []\n",
    "        metrics_pred = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i , (x , y) in enumerate(valid_dataloader):\n",
    "                x = x.to(device).float()\n",
    "                y = y.to(device)\n",
    "                with torch.cuda.amp.autocast(dtype=torch.float16 , enabled=True):\n",
    "                    output = model(x)\n",
    "                    loss = loss_fn(output , y)\n",
    "                scaler.scale(loss)\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "                metrics_true.extend(y.cpu().flatten().tolist())\n",
    "                metrics_pred.extend(torch.argmax(output , dim=-1).cpu().flatten().tolist())\n",
    "                dict_state.update({\"valid progress\" : f\"{i+1}/{len(valid_dataloader)}\"})\n",
    "                pbar.set_postfix(dict_state , refresh=(i % 10) == 0)\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        valid_loss /= len(valid_dataloader)\n",
    "        \n",
    "        valid_f_score = f1_score(metrics_true , metrics_pred , average='macro')\n",
    "        valid_accuracy = accuracy_score(metrics_true , metrics_pred)\n",
    "        \n",
    "        dict_state.update({\"train_loss\":train_loss , \"valid_loss\":valid_loss , \"valid_f1\": valid_f_score , \"valid_accuracy\":valid_accuracy})\n",
    "        pbar.set_postfix(dict_state , refresh=True)\n",
    "        \n",
    "        if best_loss > valid_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict() , \"model/play_dan_xxlarge.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
